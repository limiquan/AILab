
# 人工神经网络课程实验结果

## 1.各种训练技巧来提高模型性能

### 1.探究超参数对模型性能的影响

使用网络：resnet50
batch_size = 64
lr = 1e-3
迭代次数：100
数据集：CUB_200_2011

#### a.迭代次数的影响

| 迭代次数 | 训练集准确率 | 测试集准确率 |
| ---- | ---- | ---- |
| 50 | 0.9671 | 0.2755 |
| 100 | 0.9992 | 0.2796 |
| 150 | 0.9958 | 0.8490 |

#### b.batch_size的影响

| batch_size | 训练集准确率 | 测试集准确率 |
| ---- | ---- | ---- |
| 32 | 0.9998 | 0.8564 |
| 64 | 0.9967 | 0.8454 |
| 128 | 0.9725 | 0.7749 |

#### c.初始学习率的影响

| ini_lr | 训练集准确率 | 测试集准确率 |
| ---- | ---- | ---- |
| 1e-2 | 0.9414 | 0.8160 |
| 1e-3 | 0.9762 | 0.8273 |
| 1e-4 | 0.9967 | 0.8454 |

### 2.探究数据增强对模型性能的影响

使用网络：resnet50
batch_size = 64
lr = 1e-3
迭代次数：100

| 数据增强方式 | 训练集准确率 | 测试集准确率 |
| ---- | ---- | ---- |
| 不使用 | 1.0000 | 0.2082 |
| 随机裁剪 | 0.9992 | 0.2796 |
| 随机翻转 | 0.9992 | 0.2774 |

## 2.迁移学习

使用预训练模型的权重来进行迁移学习
使用网络：resnet101
batch_size = 64
lr = 1e-4
迭代次数：100
迁移学习策略：Transfer Learning，冻结全部卷积层，只训练前最后的fc层

| 迁移学习使用策略 | 训练集准确率 | 测试集准确率 |
| ---- | ---- | ---- |
| 不使用 | 0.9971 | 0.8398 |
| 训练layer4以及后面的层 | 1.0000 | 0.7000 |
| 训练layer3以及后面的层 | 1.0000 | 0.7342 |
| resnet152，训练layer3以及后面的层 | 1.0000 | 0.7063 |

可以发现，使用Transfer Learning训练可能不能达到比较好的效果，当我们只冻结预训练网络的前面几层，训练网络的最后三层的时候，发现模型能够更快速的收敛，并且能够达到较高得正确率，并且训练速度相比与不使用预训练模型来说更加快速，参数量更少。

## 3.图像生成

使用GAN来生成图像
在训练过程中，我们发现当判别器和生成器的学习率相等时，会出现判别器的收敛速度快于生成器的形况，导致生成图像的质量较差
我们尝试降低判别器的学习率，提高生成器的学习率，发现判别器和生成器的收敛速度较为均衡，但是可能由于训练次数较少，导致生成的图像质量也不是很理想

## 4.对比CNN模型和ViT模型

参数：
batch_size = 64
lr = 1e-4
迭代次数：100

对比各类Resnet模型和ViT模型的参数量以及再CUB_200_2011数据集上训练的收敛速度，结果如下：
|模型| 参数量 |
| ---- | ---- |
|vit_b_16| 85952456 |
|resnet50| 23917832 |
|resnet101| 42909960 |

（放两张图，对比一下resnet101和vit_b_16的收敛速度）
从上表中可以看出，ViT模型的参数量普遍大于resnet模型，这样也导致了在相同的迭代次数之下，ViT模型的收敛速度远比resnet模型要慢，并且训练时间也要更长，在本次实验中，由于vit_l_16模型的参数量过大，导致CUDA内存溢出
ViT是一种基于自注意力机制的模型，具有全局感知的特性，并且ViT模型的自注意力机制不容易实现并行计算，因此在训练过程中需要更长的时间
因此，从总体来看，ViT模型与CNN模型相比，具有更大的参数量，并且收敛速度更慢，训练时间更长，但是同时也拥有了CNN模型所不具备的全局感知特性，能够获取更多的上下文信息。同时，ViT无法利用图像本身具有的尺度、平移不变性和特征局部性等先验知识，必须使用大规模数据集学习高质量的中间表示，适合用于数据集规模较大的场景。因此，当数据集规模较大，并且训练资源较为充足的时候，使用ViT模型可能会获得更好的性能，而当数据集规模较小，或者训练资源有限时，使用CNN模型可能效果更好。

由于vit模型参数量较大，而计算资源有限，因此我们尝试使用预训练好的vit模型进行迁移学习，将预训练的vit模型与预训练的resnet模型效果进行对比，结果如下：

|模型| 训练集acc | 测试集acc |
|---- | ---- | ---- |
| vit_b_16没有冻结 | 1.0000 | 0.7510 |
| vit_b_16微调两个encoder层 | 0.9965 | 0.7332 |
| vit_b_32微调两个encoder层 | 0.9988 | 0.6018 |
| vit_l_16微调两个encoder层 | 1.0000 | 0.6800 |
| resnet152没有冻结 | 1.0000 | 0.9500 |
| resnet152微调layer3以及后面的层 | 1.0000 | 0.7063 |

通过上面的结果可以看到，使用预训练的vit模型进行迁移学习可以达到比较好的效果，由于在本次实验中使用的CUB_200_2011数据集的规模较小，因此可能无法充分发挥vit模型在大规模数据集上的优势。因此，我们可以使用预训练的vit模型进行迁移学习，以此来弥补计算资源的不足，并且达到较好的效果。
同时，对比resnet模型和vit模型，可以看到resnet模型在中等规模数据集上表现稳定，更容易收敛，而vit模型则需要更多的参数来进行学习，收敛速度较慢，并且在小规模数据集上表现较差，需要大量的数据来进行训练。

## 5.VLM

VLM模型通过从互联网上大量的图像-文本对中学习到丰富的视觉-语言关联，能够在只使用单一VLM模型的情况下实现对各种视觉任务的zero-shot迁移，在本次实验中，我们使用已经在大规模的数据上预训练好的OpenCLIP模型，并将其零样本迁移到CUB_200_2011数据集的分类任务上

我们先从CUB_200_2011数据集中抽取一张图片，利用VLM模型进行零样本分类，预测结果如下：
选取的图片：
(放一张鸟的图片：VLM_bird_1.jpg)

| text | a photo of a cat | a photo of a dog | a photo of a bird |
| ---- | ---- | ---- | ---- |
| prob | 3.6384e-04 | 3.2859e-03 | 9.9635e-01 |

从prob中可以看出，VLM模型正确预测了这张图片的内容，并且没有经过额外的数据进行训练，因此可见VLM模型具有强大的泛化能力

我们采用VLM模型对CUB_200_2011数据集的前1000张图片进行Zero-shot分类，分类的准确率为：51.4%
从VLM模型在CUB_200_2011数据集上的分类准确率可以看出，VLM模型在分类任务上具有很好的泛化能力，在没有额外数据进行训练的情况下，仅使用预训练的模型，就能够在分类任务上达到一定的准确率。其强大的泛化能力可以让我们摆脱传统机器学习中对于大量人工标注数据的依赖，通过采用一种新的学习范式–无监督预训练、微调和预测，探索自监督学习，从无标签数据中学习有用和可迁移的表征，从而获得更好的性能

接下来我们使用CoOp方法，通过学习并优化prompts，使得CLIP模型能过够适配CUB_200_2011数据集上的分类任务，增强CLIP模型的泛化能力，结果如下：

zero-shot: acc: 51.4%

CLIP + CoOp(M=16):

| mode | class token position | acc |
| ---- | --- | --- |
| zero-shot | / | 51.4% |
| 1-shot | end | 45.70% +- 0.54% |
| 2-shots | end | 52.67% +- 1.84% |
| 4-shots | end | 58.43% +- 1.33% |
| 8-shots | end | 64.80% +- 0.14% |
| 16-shots | end | 69.87% +- 0.09% |
| 16-shots | middle | 70.87% +- 0.24% |
| 16-shots-CSC | end | 69.60% +- 0.33% |

可以发现，CoOp方法使得CLIP模型在分类任务上能够达到更好的泛化能力，并且能够通过学习并优化prompts，使得CLIP模型能够适应不同的数据集，从而获得更好的性能。

## 6.可解释性

我们采用CAM方法研究模型的可解释性，根据模型最后一层卷积层的输出特征生成热力图，以此来分析模型的作用原理

我们先采用性能较差的resnet50模型进行分析，结果如下：
我们选取第0类数据作为观测的样本
当模型预测正确时，生成的热力图如下：
(CAM_resnet50_predict_true_1.jpg)
(CAM_resnet50_predict_true_2.jpg)

当模型预测错误时，生成的热力图如下：
(CAM_resnet50_predict_false_1.jpg)
(CAM_resnet50_predict_false_2.jpg)

通过生成的热力图我们可以看到，虽然模型预测了正确的结果，但是从热力图的反馈可以发现，模型并没有提取到物体的关键特征，这一点从模型预测错误的情况下生成的热力图中也可以明显看出。我们可以发现，当前的模型更多关注的时鸟的脖子部分的信息，而不是鸟的头部，嘴巴等更关键的部位。因此，我们可能需要采用更复杂的模型来使得模型能够提取到物体的关键特征，从而提高模型的性能。

## 7.模型鲁棒性

