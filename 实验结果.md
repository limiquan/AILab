
# 人工神经网络课程实验结果

## 1.各种训练技巧来提高模型性能

### 1.探究超参数对模型性能的影响

使用网络：resnet50
batch_size = 64
lr = 1e-4
迭代次数：100
数据集：CUB_200_2011

#### a.迭代次数的影响

| 迭代次数 | 训练集准确率 | 测试集准确率 |
| ---- | ---- | ---- |
| 50 | 0.9923 | 0.8401 |
| 100 | 0.9967 | 0.8454 |
| 150 | 0.9958 | 0.8490 |

#### b.batch_size的影响

| batch_size | 训练集准确率 | 测试集准确率 |
| ---- | ---- | ---- |
| 32 | 0.9998 | 0.8564 |
| 64 | 0.9967 | 0.8454 |
| 128 | 0.9725 | 0.7749 |

#### c.初始学习率的影响

| ini_lr | 训练集准确率 | 测试集准确率 |
| ---- | ---- | ---- |
| 1e-2 | 0.9414 | 0.8160 |
| 1e-3 | 0.9762 | 0.8273 |
| 1e-4 | 0.9967 | 0.8454 |

### 2.探究交叉验证对模型性能的影响

使用网络：resnet50
batch_size = 64
lr = 1e-4
迭代次数：100

| 是否使用交叉验证 | 训练集准确率 | 测试集准确率 |
| ---- | ---- | ---- |
| 不使用 | 0.9967 | 0.8454 |
| 使用 | 0.9975 | 0.8432 |

### 3.探究早停机制对模型性能的影响

使用网络：resnet50
batch_size = 64
lr = 1e-4
迭代次数：100

| 是否使用早停 | 训练集准确率 | 测试集准确率 |
| ---- | ---- | ---- |
| 不使用 | 0.9975 | 0.8452 |
| 使用 | 0.9967 | 0.8454 |

## 2.迁移学习

使用预训练模型的权重来进行迁移学习
使用网络：resnet101
batch_size = 64
lr = 1e-4
迭代次数：100
迁移学习策略：Transfer Learning，冻结全部卷积层，只训练前最后的fc层

| 迁移学习使用策略 | 训练集准确率 | 测试集准确率 |
| ---- | ---- | ---- |
| 不使用 | 0.9971 | 0.8398 |
| Transfer Learning | 0.8359 | 0.7611 |

可以发现使用迁移学习和不使用迁移学习的收敛速度相近，在30个epoch左右已经稳定下来，
但是迁移学习极大提高了训练速度,因为训练所需的参数大大减少，作为代价，准确率有所下降

## 3.图像生成

使用GAN来生成图像
在训练过程中，我们发现当判别器和生成器的学习率相等时，会出现判别器的收敛速度快于生成器的形况，导致生成图像的质量较差
我们尝试降低判别器的学习率，提高生成器的学习率，发现判别器和生成器的收敛速度较为均衡，但是可能由于训练次数较少，导致生成的图像质量也不是很理想

## 4.对比CNN模型和ViT模型

参数：
batch_size = 64
lr = 1e-4
迭代次数：100

对比各类Resnet模型和ViT模型在CUB_200_2011数据集上的性能，结果如下：
|模型| 训练集acc | 测试集acc | 参数量 |
| ---- | ---- | ---- | ---- |
|vit_b_16| 0.9166 | 0.4937 | 85952456 |
|resnet50| 0.9967 | 0.8454 | 23917832 |
|resnet101| 0.9971 | 0.8398 | 42909960 |

（放两张图，对比一下resnet101和vit_b_16的收敛速度）
从上表中可以看出，ViT模型的参数量普遍大于resnet模型，这样也导致了在相同的迭代次数之下，ViT模型的收敛速度远比resnet模型要慢，并且训练时间也要更长，在本次实验中，由于vit_l_16模型的参数量过大，导致CUDA内存溢出
ViT是一种基于自注意力机制的模型，具有全局感知的特性，并且ViT模型的自注意力机制不容易实现并行计算，因此在训练过程中需要更长的时间
因此，从总体来看，ViT模型与CNN模型相比，具有更大的参数量，并且收敛速度更慢，训练时间更长，但是同时也拥有了CNN模型所不具备的全局感知特性，能够获取更多的上下文信息。同时，ViT无法利用图像本身具有的尺度、平移不变性和特征局部性等先验知识，必须使用大规模数据集学习高质量的中间表示，适合用于数据集规模较大的场景。因此，当数据集规模较大，并且训练资源较为充足的时候，使用ViT模型可能会获得更好的性能，而当数据集规模较小，或者训练资源有限时，使用CNN模型可能效果更好。

## 5.VLM

VLM模型通过从互联网上大量的图像-文本对中学习到丰富的视觉-语言关联，能够在只使用单一VLM模型的情况下实现对各种视觉任务的zero-shot迁移，在本次实验中，我们使用已经在大规模的数据上预训练好的OpenCLIP模型，并将其零样本迁移到CUB_200_2011数据集的分类任务上

我们先从CUB_200_2011数据集中抽取一张图片，利用VLM模型进行零样本分类，预测结果如下：
选取的图片：
(放一张鸟的图片：VLM_bird_1.jpg)

| text | a photo of a cat | a photo of a dog | a photo of a bird |
| ---- | ---- | ---- | ---- |
| prob | 3.6384e-04 | 3.2859e-03 | 9.9635e-01 |

从prob中可以看出，VLM模型正确预测了这张图片的内容，并且没有经过额外的数据进行训练，因此可见VLM模型具有强大的泛化能力

我们采用VLM模型对CUB_200_2011数据集的前1000张图片进行零样本分类，分类的准确率为：49.5%
从VLM模型在CUB_200_2011数据集上的分类准确率可以看出，VLM模型在分类任务上具有很好的泛化能力，在没有额外数据进行训练的情况下，仅使用预训练的模型，就能够在分类任务上达到一定的准确率。其强大的泛化能力可以让我们摆脱传统机器学习中对于大量人工标注数据的依赖，通过采用一种新的学习范式–无监督预训练、微调和预测，探索自监督学习，从无标签数据中学习有用和可迁移的表征，从而获得更好的性能
